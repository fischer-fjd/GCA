---
title: 'Global Canopy Atlas pipeline'
author: "Fabian Fischer et al."
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty: 
    number_sections: yes
    toc: yes
    highlight: vignette
    self_contained: yes
description: >
  Generation of Digital Terrain Model (DTM) and Canopy Heigh Model (CHM) from Aerial Lidar Scanning (ALS) data
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Vignette BIOMASS}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, echo = TRUE,
  comment = "#>", fig.align = "center")
require(knitr)
```



# Recent developments

Most of th erecent effort on the development of th epipeline has been allocated towards the substitution of functions from commertial software by open source functions. This effort has been divided in two disctinct parts: the subtitution of generic functions related to filtering, cropping, reformatting, reprojecting the data and the development of dedicated functions that did not have an open source equivalent (in terms of availability and performance), such as the ground classification.

- Open source -- Ground classification

  

- Open source -- General functions


# Current challenges

- Finish the implementation of all open source functions



# Future work

1. **Complete integration of the new ground classification algorithm in the pipeline**

	The new ground classification algorithm is intended to become a more performant open source option compared to the existing algorithms in 	lidR/lasR.

	This new algorithm has been tested in a standalone approach, and validated 	with real data. The next step is to integrate it in the pipeline to have a fully 	open source pipeline with performances closer to the           commercial software 	equivalents (lastools).
  
    To do this, two solutions are possible
  
    - Direct call to the pre-compiled executable from R, as done with lastools functions
        
    - Wrap the C++ code in R to be able to be used directly from the R pipeline
    
2. **Re-factorization of the pipeline into subsets of modular functions**

	The current state of the pipeline has all the sub-functions coded in a common 	source file. This lead to a complicated readability and maintenance of the code 	base. A restructuring of this code into individual source    files for each function 	will be done to better organize the repository and have a faster maintenance 	of the pipeline.

3. **Integration and test of the pipeline in the MAAP platform**

	The Multi-Mission Algorithm and Analysis Platform is a data storage and 	computing platform put  into service by ESA. This platform is available for the 	FRM4BIOMASS/GEO-TREES actors. The platform will be used to       deploy the 	pipeline and eventually store the data from the project. 
	The pipeline is, to our current knowledge, not still operative for production 	use. Once this is the case, a deployment and test of the pipeline on the MAAP 	platform will be done. This will allow us to have a unified    reference point for 	the storage and access to the data, and to efficiently process the outputs of 	the pipeline.

4. **Consolidation of the pipeline output products**

	The pipeline, in its actual form, produces several versions of DTM and CMH 	products. This has been done in order to compare different methods, as each 	version produces the product with a different algorithm. As the pipeline 	becomes mature enough, a unique algorithm will be selected for each 	product. The other products will be optionally produced, but not by default.

5. **Formal comparison and potential merge with Marylandâ€™s university pipeline**

	In the last stages of the development, a collaboration with the university of 	Maryland has been established in the context of the GEO-TREES project. The 	team from Maryland works on their own pipeline, open-sourced,    but with 	different approaches compared to the ones used in our pipeline (notably for the DTM and CHM algorithms). 
	
	The piepline source code and documentation can be found at: https://github.com/GEO-TREES/ALS_Panama

6. **Integration of the pipeline with the AGB estimation**

    - Production ready -- Landscape statistical up-scaling (BIOMASS)
    
      Use the BIOMASS package to, using plot data of the same region scanned by the ALS data, calibrate the allometric statistical model use dfor the upscaling from the plot data to the landscape data provided by the           CHM. 
      
      More information on this approach and the package itself can be found on: https://umr-amap.github.io/BIOMASS/index.html

    - Experimental -- Individual tree based simulation (CanopyConstructor)

      Use the CanopyConstructor package, which uses the CHM and plot data to find correspondences between simulated trees and the landscape data, forming a simulated forest that can be used to generate AGB plots at any         desired raste resolution. 
      
      More information on this approach and the package itself can be found on: https://github.com/fischer-fjd/CanopyConstructor











